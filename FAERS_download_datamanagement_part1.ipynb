{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of FAERS_download_datamanagement_part1_final1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LwbkF1GMdSo"
      },
      "source": [
        "# FAERS Public dataset download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcTIxUDKMdSy"
      },
      "source": [
        "### Importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36dTcFUpMdS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821af63d-370a-4df5-dcdd-7561dce7ce78"
      },
      "source": [
        "!pip install geopandas\n",
        "import geopandas as gpd\n",
        "\n",
        "import pandas as pd\n",
        "#import vaex as vd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point\n",
        "\n",
        "#For data handling and munging. This is an extremely powerful tool\n",
        "#for working with data in a spreadsheet-like format. If you’re familiar with R data.frames, then you’ll love pandas.\n",
        "import fiona\n",
        "#fiona - For making it easy to read/write geospatial data formats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "#for plotting\n",
        "\n",
        "import os\n",
        "#sys library\n",
        "\n",
        "from functools import reduce"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.19)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.0.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4SObKK2MdS3"
      },
      "source": [
        "#importing\n",
        "#requesting files over the internet\n",
        "#import requests\n",
        "import urllib.request\n",
        "\n",
        "#unpacking zipfiles\n",
        "import zipfile\n",
        "import tarfile\n",
        "import urllib.request, shutil\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BI5L0qiNiQn"
      },
      "source": [
        "###mounting drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut_EGOgENi20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe459a5-0dfd-4de3-c7d7-cd8be6c80295"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcbGnE-kUl39"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/colab_faers_data/Data/zip')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAHnp3LuMdS6"
      },
      "source": [
        "## Importing latest FAERS dataset from openFDA api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m--N-9QYMdS7"
      },
      "source": [
        "#### brute force download (use 1 only)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFIqsfMMdS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "c4d5301d-3513-4304-c360-7f4deb4af7e2"
      },
      "source": [
        "#brute force download\n",
        "for i in range(2013,2021):\n",
        "    for j in range (1,5):\n",
        "        url = \"https://fis.fda.gov/content/Exports/faers_ascii_\"+str(i)+\"q\"+str(j)+\".zip\"#2013 and up\n",
        "        #url = \"https://fis.fda.gov/content/Exports/aers_ascii_\"+str(i)+\"q\"+str(j)+\".zip\" #earlier database\n",
        "\n",
        "        #print(i,\"_\",j)\n",
        "        print(url)\n",
        "        file_name = 'FAERS_'+str(i)+'q'+str(j)+'.zip'\n",
        "\n",
        "        with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
        "            shutil.copyfileobj(response, out_file)\n",
        "print('zipfile download complete')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://fis.fda.gov/content/Exports/faers_ascii_2013q1.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2013q2.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2013q3.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2013q4.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2014q1.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2014q2.zip\n",
            "https://fis.fda.gov/content/Exports/faers_ascii_2014q3.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-207c46509061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zipfile download complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0mtemp_mvb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0mmvb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mtotal_bytes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwKjPVdsMdS-"
      },
      "source": [
        "#### piece meal download (use 1 only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTJTNxBMdS_"
      },
      "source": [
        "###use one or the other\n",
        "###what year do you want to download\n",
        "###data starts from year 2004\n",
        "i= 2020\n",
        "###what quarter do you want to download (4 options q1, q2, q3, q4)\n",
        "j = 1#quarter\n",
        "url = \"https://fis.fda.gov/content/Exports/faers_ascii_\"+str(i)+\"q\"+str(j)+\".zip\"#2013 and up\n",
        "#url_ = \"https://fis.fda.gov/content/Exports/aers_ascii_\"+str(i_)+\"q\"+str(j_)+\".zip\" #earlier databaseprint(url_)\n",
        "file_name = 'FAERS_'+str(i)+'q'+str(j)+'.zip'\n",
        "#file_name = 'FLOODOUTLOOK_LATEST_simp_wgs84.zip'\n",
        "\n",
        "with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
        "  shutil.copyfileobj(response, out_file)\n",
        "\n",
        "print('zipfile download complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyYAkabXMdTD"
      },
      "source": [
        "### unzip  dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAQhh6eGMdTF"
      },
      "source": [
        "#### one folder at a time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgZuXq0rMdTG"
      },
      "source": [
        "i_= 2014 #year\n",
        "###what quarter do you want to download (4 options q1, q2, q3, q4)\n",
        "j_ =4 #quarter\n",
        "file_name = 'FAERS_'+str(i_)+'q'+str(j_)+'.zip'\n",
        "print(file_name)\n",
        "\n",
        "zip_path='/content/drive/MyDrive/colab_faers_data/Data/zip'\n",
        "unzip_path='/content/drive/MyDrive/colab_faers_data/Data/unzip'\n",
        "os.chdir(zip_path)\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(file_name)\n",
        "#zip_ref.printdir() \n",
        "os.chdir(unzip_path)\n",
        "zip_ref.extractall('FAERS_'+str(i_)+'q'+str(j_))\n",
        "zip_ref.close()\n",
        "print('zipfile unzip complete')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_kH3-SeMdTI"
      },
      "source": [
        "#### batch unzip folders "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuNGbSZgMdTJ"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "for i_ in range(2013, 2015):\n",
        "    for j_ in range (1,5):\n",
        "        zip_path='/content/drive/MyDrive/colab_faers_data/Data/zip'\n",
        "        unzip_path='/content/drive/MyDrive/colab_faers_data/Data/unzip'\n",
        "\n",
        "        #zip_path = r\"D:\\Research\\FAERS_Public\\Data_20210222\\Orignal_data\\zipfile_data\"\n",
        "       # unzip_path = r\"D:\\Research\\FAERS_Public\\Data_20210222\\Orignal_data\\unzipped_data\"\n",
        "        os.chdir(zip_path)\n",
        "        file_name = 'FAERS_'+str(i_)+'q'+str(j_)+'.zip'\n",
        "        print(file_name)\n",
        "        zip_ref = zipfile.ZipFile(file_name)\n",
        "#zip_ref.printdir() \n",
        "        os.chdir(unzip_path)\n",
        "        zip_ref.extractall('FAERS_'+str(i_)+'q'+str(j_))\n",
        "        zip_ref.close()\n",
        "        print('zipfile unzip complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkrdbMegPpj"
      },
      "source": [
        "#####change files names here\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3UOcFEtgPTI"
      },
      "source": [
        "#os.chdir('/content/drive/MyDrive/colab_faers_data/Data/zip')\n",
        " \n",
        "os.rename(\"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2018q1/ascii/DEMO18Q1_new.txt\",\n",
        "          \"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2018q1/ascii/DEMO18Q1.txt\")\n",
        "os.rename(\"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2013q3/ASCII\",\n",
        "\"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2013q3/ascii\")\n",
        "for i_ in range(2020, 2021):\n",
        "    for j_ in range (1,5):\n",
        "        os.rename(\"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_\"+str(i_)+\"q\"+str(j_)+\"/ASCII\",\n",
        "          \"/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_\"+str(i_)+\"q\"+str(j_)+\"/ascii\")\n",
        "        print(i_,j_)\n",
        "\n",
        "print(\"The File has been successfully renamed!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lerpIYVnssEH"
      },
      "source": [
        "#####change column names here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IbmxNUjuMo5"
      },
      "source": [
        "file = pd.read_csv('/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2014q1/ascii/DEMO14Q1.txt',delimiter=\"$\",error_bad_lines=False, encoding='utf-8')\n",
        "#file.rename(columns = {'gndr_cod': 'sex'}, inplace = True)\n",
        "#file.to_csv('/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_2014q1/ascii/DEMO14Q1.txt',sep=\"$\")\n",
        "\n",
        "file.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4wWQHrWi1pv"
      },
      "source": [
        "###Reading files \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndnldy9me4Sc"
      },
      "source": [
        "after **2018** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1YmzQioj0WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47300f16-db47-45ca-e7c1-6d19e120f7c2"
      },
      "source": [
        "df1_appended_data0 = []\n",
        "df2_appended_data0 = []\n",
        "df3_appended_data0 = []\n",
        "#df4_appended_data0 = []\n",
        "df5_appended_data0 = []\n",
        "#df6_appended_data0 = []\n",
        "#df7_appended_data0 = []\n",
        "chunk_size=5000\n",
        "for i in range(2020,2021):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "      \n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data0.append(df1)\n",
        "        df2_appended_data0.append(df2)\n",
        "        df3_appended_data0.append(df3)\n",
        "        #df4_appended_data0.append(df4)\n",
        "        df5_appended_data0.append(df5)\n",
        "        #df6_appended_data0.append(df6)\n",
        "        #df7_appended_data0.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data0 = pd.concat(df1_appended_data0, axis=0)\n",
        "df2_appended_data0 = pd.concat(df2_appended_data0, axis=0)\n",
        "df3_appended_data0 = pd.concat(df3_appended_data0, axis=0)\n",
        "#df4_appended_data0 = pd.concat(df4_appended_data0, axis=0)\n",
        "df5_appended_data0 = pd.concat(df5_appended_data0, axis=0)\n",
        "#df6_appended_data0 = pd.concat(df6_appended_data0, axis=0)\n",
        "#df7_appended_data0 = pd.concat(df7_appended_data0, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "1\n",
            "20\n",
            "2\n",
            "20\n",
            "3\n",
            "20\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6WoG5Wgiymd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8199ed3-10d5-4bcb-e6f9-0f48eee4fe9d"
      },
      "source": [
        "df1_appended_data0b = []\n",
        "df2_appended_data0b = []\n",
        "df3_appended_data0b = []\n",
        "#df4_appended_data0b = []\n",
        "df5_appended_data0b = []\n",
        "#df6_appended_data0b = []\n",
        "#df7_appended_data0b = []\n",
        "\n",
        "for i in range(2019,2020):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "      \n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data0b.append(df1)\n",
        "        df2_appended_data0b.append(df2)\n",
        "        df3_appended_data0b.append(df3)\n",
        "        #df4_appended_data0b.append(df4)\n",
        "        df5_appended_data0b.append(df5)\n",
        "        #df6_appended_data0b.append(df6)\n",
        "        #df7_appended_data0b.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data0b = pd.concat(df1_appended_data0b, axis=0)\n",
        "df2_appended_data0b = pd.concat(df2_appended_data0b, axis=0)\n",
        "df3_appended_data0b = pd.concat(df3_appended_data0b, axis=0)\n",
        "#df4_appended_data0b = pd.concat(df4_appended_data0b, axis=0)\n",
        "df5_appended_data0b = pd.concat(df5_appended_data0b, axis=0)\n",
        "#df6_appended_data0b = pd.concat(df6_appended_data0b, axis=0)\n",
        "#df7_appended_data0b = pd.concat(df7_appended_data0b, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "1\n",
            "19\n",
            "2\n",
            "19\n",
            "3\n",
            "19\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJqXfhcMYyiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b8e852-ac33-4a3a-938b-a7d4df0fca6f"
      },
      "source": [
        "df1_appended_data0c = []\n",
        "df2_appended_data0c = []\n",
        "df3_appended_data0c = []\n",
        "#df4_appended_data0c = []\n",
        "df5_appended_data0c = []\n",
        "#df6_appended_data0c = []\n",
        "#df7_appended_data0c = []\n",
        "\n",
        "for i in range(2018,2019):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "      \n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data0c.append(df1)\n",
        "        df2_appended_data0c.append(df2)\n",
        "        df3_appended_data0c.append(df3)\n",
        "        #df4_appended_data0c.append(df4)\n",
        "        df5_appended_data0c.append(df5)\n",
        "        #df6_appended_data0c.append(df6)\n",
        "        #df7_appended_data0c.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data0c = pd.concat(df1_appended_data0c, axis=0)\n",
        "df2_appended_data0c = pd.concat(df2_appended_data0c, axis=0)\n",
        "df3_appended_data0c = pd.concat(df3_appended_data0c, axis=0)\n",
        "#df4_appended_data0c = pd.concat(df4_appended_data0c, axis=0)\n",
        "df5_appended_data0c = pd.concat(df5_appended_data0c, axis=0)\n",
        "#df6_appended_data0c = pd.concat(df6_appended_data0c, axis=0)\n",
        "#df7_appended_data0c = pd.concat(df7_appended_data0c, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "1\n",
            "18\n",
            "2\n",
            "18\n",
            "3\n",
            "18\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHYJbvriejnE"
      },
      "source": [
        "2015 to **2017**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c41anGkEMdTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3db06a-96eb-46df-bd3e-74c359ba610e"
      },
      "source": [
        "df1_appended_data1a = []\n",
        "df2_appended_data1a = []\n",
        "df3_appended_data1a = []\n",
        "#df4_appended_data1a = []\n",
        "df5_appended_data1a = []\n",
        "#df6_appended_data1a = []\n",
        "#df7_appended_data1a = []\n",
        "\n",
        "for i in range(2017,2018):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data1a.append(df1)\n",
        "        df2_appended_data1a.append(df2)\n",
        "        df3_appended_data1a.append(df3)\n",
        "        #df4_appended_data1a.append(df4)\n",
        "        df5_appended_data1a.append(df5)\n",
        "        #df6_appended_data1a.append(df6)\n",
        "        #df7_appended_data1a.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data1a = pd.concat(df1_appended_data1a, axis=0)\n",
        "df2_appended_data1a = pd.concat(df2_appended_data1a, axis=0)\n",
        "df3_appended_data1a = pd.concat(df3_appended_data1a, axis=0)\n",
        "#df4_appended_data1a = pd.concat(df4_appended_data1a, axis=0)\n",
        "df5_appended_data1a = pd.concat(df5_appended_data1a, axis=0)\n",
        "#df6_appended_data1a = pd.concat(df6_appended_data1a, axis=0)\n",
        "#df7_appended_data1a = pd.concat(df7_appended_data1a, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "1\n",
            "17\n",
            "2\n",
            "17\n",
            "3\n",
            "17\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVkn__3m4Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308923d1-0b59-4a32-ffa6-865ebfff93c0"
      },
      "source": [
        "df1_appended_data1b = []\n",
        "df2_appended_data1b = []\n",
        "df3_appended_data1b = []\n",
        "#df4_appended_data1b = []\n",
        "df5_appended_data1b = []\n",
        "#df6_appended_data1b = []\n",
        "#df7_appended_data1b = []\n",
        "\n",
        "for i in range(2016,2017):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data1b.append(df1)\n",
        "        df2_appended_data1b.append(df2)\n",
        "        df3_appended_data1b.append(df3)\n",
        "        #df4_appended_data1b.append(df4)\n",
        "        df5_appended_data1b.append(df5)\n",
        "        #df6_appended_data1b.append(df6)\n",
        "        #df7_appended_data1b.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data1b = pd.concat(df1_appended_data1b, axis=0)\n",
        "df2_appended_data1b = pd.concat(df2_appended_data1b, axis=0)\n",
        "df3_appended_data1b = pd.concat(df3_appended_data1b, axis=0)\n",
        "#df4_appended_data1b = pd.concat(df4_appended_data1b, axis=0)\n",
        "df5_appended_data1b = pd.concat(df5_appended_data1b, axis=0)\n",
        "#df6_appended_data1b = pd.concat(df6_appended_data1b, axis=0)\n",
        "#df7_appended_data1b = pd.concat(df7_appended_data1b, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "1\n",
            "16\n",
            "2\n",
            "16\n",
            "3\n",
            "16\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cwX9_d2m42k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48d9239-cfa6-411f-ebf4-1cf52a77ab53"
      },
      "source": [
        "df1_appended_data1c = []\n",
        "df2_appended_data1c = []\n",
        "df3_appended_data1c = []\n",
        "#df4_appended_data1c = []\n",
        "df5_appended_data1c = []\n",
        "#df6_appended_data1c = []\n",
        "#df7_appended_data1c = []\n",
        "\n",
        "for i in range(2015,2016):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,delimiter=\"$\",error_bad_lines=False, encoding=\"cp1252\", usecols=usecols2)\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\", usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,delimiter=\"$\",error_bad_lines=False, encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "       # print(df2.columns)\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "\n",
        "        df1_appended_data1c.append(df1)\n",
        "        df2_appended_data1c.append(df2)\n",
        "        df3_appended_data1c.append(df3)\n",
        "        #df4_appended_data1c.append(df4)\n",
        "        df5_appended_data1c.append(df5)\n",
        "        #df6_appended_data1c.append(df6)\n",
        "        #df7_appended_data1c.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data1c = pd.concat(df1_appended_data1c, axis=0)\n",
        "df2_appended_data1c = pd.concat(df2_appended_data1c, axis=0)\n",
        "df3_appended_data1c = pd.concat(df3_appended_data1c, axis=0)\n",
        "#df4_appended_data1c = pd.concat(df4_appended_data1c, axis=0)\n",
        "df5_appended_data1c = pd.concat(df5_appended_data1c, axis=0)\n",
        "#df6_appended_data1c = pd.concat(df6_appended_data1c, axis=0)\n",
        "#df7_appended_data1c = pd.concat(df7_appended_data1c, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "1\n",
            "15\n",
            "2\n",
            "15\n",
            "3\n",
            "15\n",
            "4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9N6JO9tV7J1"
      },
      "source": [
        "2013 and 2014"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sycs8ENIMdTQ",
        "outputId": "ca9647ac-b48f-4b04-9d2b-ac0f66ccd360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1_appended_data2a = []\n",
        "df2_appended_data2a = []\n",
        "df3_appended_data2a = []\n",
        "#df4_appended_data2a = []\n",
        "df5_appended_data2a = []\n",
        "#df6_appended_data2a = []\n",
        "#df7_appended_data2a = []\n",
        "\n",
        "for i in range(2014,2015):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding=\"cp1252\")\n",
        "        df2 =df2[df2.columns[[0,1,4,-1]]]\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\" ,usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "        df1_appended_data2a.append(df1)\n",
        "        df2_appended_data2a.append(df2)\n",
        "        df3_appended_data2a.append(df3)\n",
        "      #  df4_appended_data2a.append(df4)\n",
        "        df5_appended_data2a.append(df5)\n",
        "      #  df6_appended_data2a.append(df6)\n",
        "       # df7_appended_data2a.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data2a = pd.concat(df1_appended_data2a, axis=0)\n",
        "df2_appended_data2a = pd.concat(df2_appended_data2a, axis=0)\n",
        "\n",
        "df3_appended_data2a = pd.concat(df3_appended_data2a, axis=0)\n",
        "#df4_appended_data2a = pd.concat(df4_appended_data2a, axis=0)\n",
        "df5_appended_data2a = pd.concat(df5_appended_data2a, axis=0)\n",
        "#df6_appended_data2a = pd.concat(df6_appended_data2a, axis=0)\n",
        "#df7_appended_data2a = pd.concat(df7_appended_data2a, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10,11,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyYJR7ljnzf8",
        "outputId": "22368556-a6a0-4029-8e14-f9bcd60d1f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1_appended_data2b = []\n",
        "df2_appended_data2b = []\n",
        "df3_appended_data2b = []\n",
        "#df4_appended_data2b = []\n",
        "df5_appended_data2b = []\n",
        "#df6_appended_data2b = []\n",
        "#df7_appended_data2b = []\n",
        "\n",
        "for i in range(2013,2014):\n",
        "    for j in range (1,5):\n",
        "        ii = str(i)\n",
        "        ii =(ii[-2:])\n",
        "        print(ii)\n",
        "        print(j)\n",
        "        df1_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DEMO'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df2_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'DRUG'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df3_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'INDI'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df4_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'OUTC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        df5_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'REAC'+str(ii)+'Q'+str(j)+'.txt'\n",
        "\n",
        "        #df6_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'RPSR'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        #df7_filepath =  '/content/drive/MyDrive/colab_faers_data/Data/unzip/FAERS_'+str(i)+'q'+str(j)+'/'+'ascii'+'/'+'THER'+str(ii)+'Q'+str(j)+'.txt'\n",
        "        usecols1=[\"primaryid\",\"caseid\", \"event_dt\",\"occr_country\", 'age', 'sex' ]\n",
        "        usecols2=[\"primaryid\",\"caseid\", \"drugname\",\"prod_ai\"]\n",
        "        usecols3=[\"primaryid\",\"caseid\", \"indi_pt\"]\n",
        "        usecols5=[\"primaryid\",\"caseid\", \"pt\"]\n",
        "\n",
        "\n",
        "        df1 = pd.read_csv(df1_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding='utf-8', usecols=usecols1)\n",
        "        df2 = pd.read_csv(df2_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding=\"cp1252\")\n",
        "        df2 =df2[df2.columns[[0,1,4,-1]]]\n",
        "        df3 = pd.read_csv(df3_filepath,delimiter=\"$\" ,usecols=usecols3)\n",
        "        #df4 = pd.read_csv(df4_filepath,delimiter=\"$\")\n",
        "        df5 = pd.read_csv(df5_filepath,error_bad_lines=False,delimiter=\"$\" ,encoding='utf-8', usecols=usecols5)\n",
        "        #df6 = pd.read_csv(df6_filepath,delimiter=\"$\")\n",
        "        #df7 = pd.read_csv(df7_filepath,delimiter=\"$\")\n",
        "\n",
        "        df1.columns = df1.columns.str.lower()  \n",
        "        df2.columns = df2.columns.str.lower()  \n",
        "        df3.columns = df3.columns.str.lower()  \n",
        "        #df4.columns = df4.columns.str.lower()  \n",
        "        df5.columns = df5.columns.str.lower() \n",
        "        #df6.columns = df6.columns.str.lower()  \n",
        "        #df7.columns = df7.columns.str.lower() \n",
        "\n",
        "        df1_appended_data2b.append(df1)\n",
        "        df2_appended_data2b.append(df2)\n",
        "        df3_appended_data2b.append(df3)\n",
        "      #  df4_appended_data2b.append(df4)\n",
        "        df5_appended_data2b.append(df5)\n",
        "      #  df6_appended_data2b.append(df6)\n",
        "       # df7_appended_data2b.append(df7)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "df1_appended_data2b = pd.concat(df1_appended_data2b, axis=0)\n",
        "df2_appended_data2b = pd.concat(df2_appended_data2b, axis=0)\n",
        "\n",
        "df3_appended_data2b = pd.concat(df3_appended_data2b, axis=0)\n",
        "#df4_appended_data2b = pd.concat(df4_appended_data2b, axis=0)\n",
        "df5_appended_data2b = pd.concat(df5_appended_data2b, axis=0)\n",
        "#df6_appended_data2b = pd.concat(df6_appended_data2b, axis=0)\n",
        "#df7_appended_data2b = pd.concat(df7_appended_data2b, axis=0)\n",
        "print('done')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,10,13,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (11,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN9kkhAqqZJe"
      },
      "source": [
        "### Data management (drugname column)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mco7mdLq4yM"
      },
      "source": [
        "##### data management (drugname column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Nx_jiTA_C4",
        "outputId": "5cfbfc1b-0763-4349-c858-1c58122b442d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "df2_appended_data0['drugname']= df2_appended_data0['drugname'].str.lower()\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.strip()\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.strip(',')\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('\\n',\"\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data0['drugname'] = [''.join(c.split()) for c in df2_appended_data0['drugname'].astype(str)]\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-04391d92b2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"\\\\\\\\\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_appended_data0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"' \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, pat, repl, n, case, flags, regex)\u001b[0m\n\u001b[1;32m   2843\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m         result = str_replace(\n\u001b[0;32m-> 2845\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m         )\n\u001b[1;32m   2847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_replace\u001b[0;34m(arr, pat, repl, n, case, flags, regex)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_compiled_re\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IECDAShIMdTV"
      },
      "source": [
        "\n",
        "df2_appended_data0['drugname']= df2_appended_data0['drugname'].str.lower()\n",
        "df2_appended_data0b['drugname']= df2_appended_data0b['drugname'].str.lower()\n",
        "df2_appended_data0c['drugname']= df2_appended_data0c['drugname'].str.lower()\n",
        "\n",
        "df2_appended_data1a['drugname']= df2_appended_data1a['drugname'].str.lower()\n",
        "df2_appended_data1b['drugname']= df2_appended_data1b['drugname'].str.lower()\n",
        "df2_appended_data1c['drugname']= df2_appended_data1c['drugname'].str.lower()\n",
        "\n",
        "df2_appended_data2a['drugname']= df2_appended_data2a['drugname'].str.lower()\n",
        "df2_appended_data2b['drugname']= df2_appended_data2b['drugname'].str.lower()\n",
        "\n",
        "#############################\n",
        "\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.strip()\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.strip(',')\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('\\n',\"\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data0['drugname'] = [''.join(c.split()) for c in df2_appended_data0['drugname'].astype(str)]\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data0['drugname'] = df2_appended_data0['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "########################\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.strip()\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.strip(',')\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace('\\n',\"\")\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data0b['drugname'] = [''.join(c.split()) for c in df2_appended_data0b['drugname'].astype(str)]\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data0b['drugname'] = df2_appended_data0b['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "#############################\n",
        "\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.strip()\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.strip(',')\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace('\\n',\"\")\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data0c['drugname'] = [''.join(c.split()) for c in df2_appended_data0c['drugname'].astype(str)]\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data0c['drugname'] = df2_appended_data0c['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "####################\n",
        "\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.strip()\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.strip(',')\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace(' \\n',\"\")\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data1a['drugname'] = [''.join(c.split()) for c in df2_appended_data1a['drugname'].astype(str)]\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data1a['drugname'] = df2_appended_data1a['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "####################\n",
        "\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.strip()\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.strip(',')\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace(' \\n',\"\")\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data1b['drugname'] = [''.join(c.split()) for c in df2_appended_data1b['drugname'].astype(str)]\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data1b['drugname'] = df2_appended_data1b['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "####################\n",
        "\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.strip()\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.strip(',')\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace(' \\n',\"\")\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data1c['drugname'] = [''.join(c.split()) for c in df2_appended_data1c['drugname'].astype(str)]\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data1c['drugname'] = df2_appended_data1c['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "########################\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.strip()\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.strip(',')\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace(' \\n',\"\")\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data2a['drugname'] = [''.join(c.split()) for c in df2_appended_data2a['drugname'].astype(str)]\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data2a['drugname'] = df2_appended_data2a['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n",
        "\n",
        "########################\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.strip()\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.strip(',')\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace(u\"/\",\", \")\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace(u\"\\\\\\\\\", \", \")\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace(u\"' \",\"'\")\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace('.',\"\")\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace(' \\n',\"\")\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.replace('\\n ',\"\")\n",
        "df2_appended_data2b['drugname'] = [''.join(c.split()) for c in df2_appended_data2b['drugname'].astype(str)]\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
        "df2_appended_data2b['drugname'] = df2_appended_data2b['drugname'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFppkXvxkgJ_"
      },
      "source": [
        "#os.chdir('/content/drive/MyDrive/colab_faers_data/Data/helper_dataset')\n",
        "##country_file_url = 'https://opendata.arcgis.com/datasets/2b93b06dc0dc4e809d3c8db5cb96ba69_0.zip'\n",
        "#file_name = 'world'+'.zip'\n",
        "\n",
        "#with urllib.request.urlopen(country_file_url) as response, open(file_name, 'wb') as out_file:\n",
        " # shutil.copyfileobj(response, out_file)\n",
        "\n",
        "#print('zipfile download complete')\n",
        "\n",
        "#file_name = 'world'+'.zip'\n",
        "#print(file_name)\n",
        "\n",
        "#os.chdir('/content/drive/MyDrive/colab_faers_data/Data/helper_dataset')\n",
        "#import zipfile\n",
        "#zip_ref = zipfile.ZipFile(file_name)\n",
        "#zip_ref.printdir() \n",
        "#os.chdir('/content/drive/MyDrive/colab_faers_data/Data/helper_dataset')\n",
        "#zip_ref.extractall('world')\n",
        "#zip_ref.close()\n",
        "#print('zipfile unzip complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAJI9GN7q-Ev"
      },
      "source": [
        "#####country shapefile - download and joining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DndoCH3fMdTX"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/colab_faers_data/Data/helper_dataset/world')\n",
        "\n",
        "world_shp = gpd.read_file(filename='World_Countries__Generalized_.shp')\n",
        "world_shp['ISO'] = world_shp['ISO'].str.strip()#ISOSHRTNAM\n",
        "world_shp['ISO'] = world_shp['ISO'].str.lower()\n",
        "europe = ['AL', 'AD', 'AM', 'AT', 'BY', 'BE', 'BA', 'BG', 'CH', 'CY', 'CZ', 'DE',\n",
        "        'DK', 'EE', 'ES', 'FO', 'FI', 'FR', 'GB', 'GE', 'GI', 'GR', 'HU', 'HR',\n",
        "        'IE', 'IS', 'IT', 'LT', 'LU', 'LV', 'MC', 'MK', 'MT', 'NO', 'NL', 'PL',\n",
        "        'PT', 'RO', 'SE', 'SI', 'SK', 'SM', 'TR', 'UA', 'VA']\n",
        "world_shp = world_shp[world_shp['ISO'].str.contains('|'.join(europe),case=False, na=False, regex=True)]\n",
        "world_shp['centroid'] = world_shp['geometry'].centroid\n",
        "world_shp['coords'] = world_shp['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
        "world_shp['coords'] = [coords[0] for coords in world_shp['coords']]\n",
        "world_shp['coords']\n",
        "\n",
        "world_shp['Lon'] = world_shp.centroid.x\n",
        "world_shp['Lat'] = world_shp.centroid.y\n",
        "\n",
        "world_shp = world_shp.reset_index()\n",
        "world_shp.columns\n",
        "#world_shp.head()\n",
        "world_shp[['COUNTRY','ISO','geometry','coords']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwwucfj5MdTY"
      },
      "source": [
        "df1_appended_data0['occr_country'] = df1_appended_data0['occr_country'].str.strip()\n",
        "df1_appended_data0['occr_country'] = df1_appended_data0['occr_country'].str.lower()\n",
        "\n",
        "df_e0 =df1_appended_data0.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUAZsqUUndIO"
      },
      "source": [
        "df1_appended_data0b['occr_country'] = df1_appended_data0b['occr_country'].str.strip()\n",
        "df1_appended_data0b['occr_country'] = df1_appended_data0b['occr_country'].str.lower()\n",
        "\n",
        "df_e0b =df1_appended_data0b.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVoZBtlRtzj"
      },
      "source": [
        "df1_appended_data0c['occr_country'] = df1_appended_data0c['occr_country'].str.strip()\n",
        "df1_appended_data0c['occr_country'] = df1_appended_data0c['occr_country'].str.lower()\n",
        "\n",
        "df_e0c =df1_appended_data0.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF-C_4s3MdTZ"
      },
      "source": [
        "df1_appended_data1a['occr_country'] = df1_appended_data1a['occr_country'].str.strip()\n",
        "df1_appended_data1a['occr_country'] = df1_appended_data1a['occr_country'].str.lower()\n",
        "\n",
        "df_e1a =df1_appended_data1a.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8ww4ir4RtpL"
      },
      "source": [
        "df1_appended_data1b['occr_country'] = df1_appended_data1b['occr_country'].str.strip()\n",
        "df1_appended_data1b['occr_country'] = df1_appended_data1b['occr_country'].str.lower()\n",
        "\n",
        "df_e1b =df1_appended_data1b.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Im1_XUTndTr"
      },
      "source": [
        "df1_appended_data1c['occr_country'] = df1_appended_data1c['occr_country'].str.strip()\n",
        "df1_appended_data1c['occr_country'] = df1_appended_data1c['occr_country'].str.lower()\n",
        "\n",
        "df_e1c =df1_appended_data1c.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MckEytWPMdTa"
      },
      "source": [
        "df1_appended_data2a['occr_country'] = df1_appended_data2a['occr_country'].str.strip()\n",
        "df1_appended_data2a['occr_country'] = df1_appended_data2a['occr_country'].str.lower()\n",
        "\n",
        "df_e2a =df1_appended_data2a.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_FDzK_vS1tA"
      },
      "source": [
        "df1_appended_data2b['occr_country'] = df1_appended_data2b['occr_country'].str.strip()\n",
        "df1_appended_data2b['occr_country'] = df1_appended_data2b['occr_country'].str.lower()\n",
        "\n",
        "df_e2b =df1_appended_data2b.merge(world_shp[['COUNTRY','ISO','geometry','coords']], left_on='occr_country', right_on='ISO', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTCCinviMdTb"
      },
      "source": [
        "import gc\n",
        "collected = gc.collect()\n",
        "gc.collect()\n",
        "\n",
        "print (\"Garbage collector: collected %d objects.\" % (collected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV1DkQaerdBd"
      },
      "source": [
        "##### data management (joining all dataframes together)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcEIogx7MdTb"
      },
      "source": [
        "data_frames0 = [df_e0, df2_appended_data0,df3_appended_data0,df5_appended_data0]\n",
        "df_merged0 = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames0)\n",
        "\n",
        "#df_merged0.head()\n",
        "#dd = df_merged0[['caseid_x', 'caseid_y','caseid']]\n",
        "#duplicateRowsDF1 = dd.drop_duplicates(subset=['caseid_x', 'caseid_y','caseid'], keep='last')\n",
        "#duplicateRowsDF = duplicateRowsDF1.drop_duplicates(subset=['caseid_x', 'caseid_y','caseid'], keep=False)\n",
        "#duplicateRowsDF\n",
        "#duplicateRowsDF1 = duplicateRowsDF1.T.drop_duplicates().T\n",
        "#duplicateRowsDF1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whooEIHyU85D"
      },
      "source": [
        "df_merged0.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6W2m1UdTPJG"
      },
      "source": [
        "data_frames0b = [df_e0b, df2_appended_data0b,df3_appended_data0b,df5_appended_data0b]\n",
        "df_merged0b = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames0b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjKM9h-vkdd3"
      },
      "source": [
        "df_merged0b.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0b.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrx1dnITUlPc"
      },
      "source": [
        "del(df_e0b, df2_appended_data0b,df3_appended_data0b,df5_appended_data0b,data_frames0b) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sczrADAtTPZW"
      },
      "source": [
        "data_frames0c = [df_e0c, df2_appended_data0c,df3_appended_data0c,df5_appended_data0c]\n",
        "df_merged0c = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames0c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EioYcV2Iky_S"
      },
      "source": [
        "df_merged0c.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0c.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX_mMBgmMdTd"
      },
      "source": [
        "data_frames1a = [df_e1a, df2_appended_data1a,df3_appended_data1a,df5_appended_data1a]\n",
        "\n",
        "df_merged1a = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames1a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3y7zjQoldNg"
      },
      "source": [
        "df_merged1a.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_RJ3Stn43g"
      },
      "source": [
        "data_frames1b = [df_e1b, df2_appended_data1b,df3_appended_data1b,df5_appended_data1b]\n",
        "df_merged1b = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames1b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxq-xCldlgIj"
      },
      "source": [
        "df_merged1b.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1b.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhqrZmKgn5EQ"
      },
      "source": [
        "data_frames1c = [df_e1c, df2_appended_data1c,df3_appended_data1c,df5_appended_data1c]\n",
        "df_merged1c = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames1c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxWmKzNelk91"
      },
      "source": [
        "df_merged1c.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1c.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uciZZcNAMdTe"
      },
      "source": [
        "data_frames2a = [df_e2a, df2_appended_data2a,df3_appended_data2a,df5_appended_data2a]\n",
        "df_merged2a = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames2a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEMMcQMkmnF3"
      },
      "source": [
        "df_merged2a.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged2a.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_q1tDNomnoP"
      },
      "source": [
        "data_frames2b = [df_e2b, df2_appended_data2b,df3_appended_data2b,df5_appended_data2b]\n",
        "df_merged2b = reduce(lambda  left,right: pd.merge(left,right,on=['primaryid','caseid'],\n",
        "                                            how='inner'), data_frames2b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1O1EDOimn15"
      },
      "source": [
        "df_merged2b.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged2b.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmVcFUitnHYT"
      },
      "source": [
        "stop\n",
        "#df_merged2b.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDWTsXN1rnYO"
      },
      "source": [
        "##### data management (time column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFXU4vbCxAg3"
      },
      "source": [
        "!pip install geopandas\n",
        "import geopandas as gpd\n",
        "\n",
        "import pandas as pd\n",
        "#import vaex as vd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point\n",
        "\n",
        "#For data handling and munging. This is an extremely powerful tool\n",
        "#for working with data in a spreadsheet-like format. If you’re familiar with R data.frames, then you’ll love pandas.\n",
        "import fiona\n",
        "#fiona - For making it easy to read/write geospatial data formats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "#for plotting\n",
        "\n",
        "import os\n",
        "#sys library\n",
        "\n",
        "from functools import reduce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlTN7pd4MdTh"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76MTZtITMdTi"
      },
      "source": [
        "#df_merged0 = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0.pkl')\n",
        "df_merged0b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0b.pkl')\n",
        "\n",
        "df_merged0b['occr_country'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPfi7B3fvQTj"
      },
      "source": [
        "df_merged0b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0b.pkl')\n",
        "df_merged0c = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0c.pkl')\n",
        "df_merged1a = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl')\n",
        "df_merged1b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1b.pkl')\n",
        "df_merged1c = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1c.pkl')\n",
        "df_merged2a = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged2a.pkl')\n",
        "df_merged2b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged2b.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q18Vo4voMdTi"
      },
      "source": [
        "df_merged0 = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0.pkl')\n",
        "\n",
        "df_merged0['event_dt'] = df_merged0['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged0['event_dt'] = df_merged0['event_dt'].astype(str)\n",
        "df_merged0.fillna(0)\n",
        "df_merged0.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged0['event_dt'] = pd.to_datetime(df_merged0.event_dt, errors='coerce')\n",
        "#df_merged0['event_dt1'] = df_merged0['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged0.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0.pkl') \n",
        "\n",
        "df_merged0.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F4DKYICvmu2"
      },
      "source": [
        "df_merged0b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0b.pkl')\n",
        "\n",
        "df_merged0b['event_dt'] = df_merged0b['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged0b['event_dt'] = df_merged0b['event_dt'].astype(str)\n",
        "df_merged0b.fillna(0)\n",
        "df_merged0b.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged0b['event_dt'] = pd.to_datetime(df_merged0b.event_dt, errors='coerce')\n",
        "#df_merged0b['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged0b.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0b.pkl') \n",
        "\n",
        "df_merged0b.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-axuQCF_9QA"
      },
      "source": [
        "df_merged0c = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0c.pkl')\n",
        "\n",
        "df_merged0c['event_dt'] = df_merged0c['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged0c['event_dt'] = df_merged0c['event_dt'].astype(str)\n",
        "df_merged0c.fillna(0)\n",
        "df_merged0c.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged0c['event_dt'] = pd.to_datetime(df_merged0c.event_dt, errors='coerce')\n",
        "#df_merged0b['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged0c.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged0c.pkl') \n",
        "\n",
        "df_merged0c.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biPQjYktMdTj"
      },
      "source": [
        "df_merged1a = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl')\n",
        "\n",
        "df_merged1a['event_dt'] = df_merged1a['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged1a['event_dt'] = df_merged1a['event_dt'].astype(str)\n",
        "df_merged1a.fillna(0)\n",
        "df_merged1a.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged1a['event_dt'] = pd.to_datetime(df_merged1a.event_dt, errors='coerce')\n",
        "#df_merged0b['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged1a.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl') \n",
        "\n",
        "df_merged1a.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRAfMMWYUr46"
      },
      "source": [
        "df_merged1b = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1b.pkl')\n",
        "\n",
        "df_merged1b['event_dt'] = df_merged1b['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged1b['event_dt'] = df_merged1b['event_dt'].astype(str)\n",
        "df_merged1b.fillna(0)\n",
        "df_merged1b.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged1b['event_dt'] = pd.to_datetime(df_merged1b.event_dt, errors='coerce')\n",
        "#df_merged0b['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged1b.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1b.pkl') \n",
        "\n",
        "df_merged1b.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ9ALEoDU6RS"
      },
      "source": [
        "df_merged1c = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1c.pkl')\n",
        "\n",
        "df_merged1c['event_dt'] = df_merged1c['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged1c['event_dt'] = df_merged1c['event_dt'].astype(str)\n",
        "df_merged1c.fillna(0)\n",
        "df_merged1c.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged1c['event_dt'] = pd.to_datetime(df_merged1c.event_dt, errors='coerce')\n",
        "#df_merged1c['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged1c.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1c.pkl') \n",
        "\n",
        "df_merged1c.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DjSr4FVMdTj"
      },
      "source": [
        "df_merged2a = pd.read_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl')\n",
        "\n",
        "df_merged2a['event_dt'] = df_merged1a['event_dt'].astype(str).replace('\\.0', '', regex=True)\n",
        "df_merged2a['event_dt'] = df_merged1a['event_dt'].astype(str)\n",
        "df_merged2a.fillna(0)\n",
        "df_merged2a.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "df_merged2a['event_dt'] = pd.to_datetime(df_merged1a.event_dt, errors='coerce')\n",
        "#df_merged0b['event_dt1'] = df_merged0b['event_dt'].dt.strftime('%Y%m%d')\n",
        "df_merged1a.to_pickle('/content/drive/MyDrive/colab_faers_data/Data/temp_data/df_merged1a.pkl') \n",
        "\n",
        "df_merged1a.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWcN0z9Qr7Eu"
      },
      "source": [
        "##### brining all frames together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR8OV1WLMdTm"
      },
      "source": [
        "df_merged0_=df_merged0\n",
        "df_merged1_=df_merged1\n",
        "df_merged2_=df_merged2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tns-4UfcMdTn"
      },
      "source": [
        "\n",
        "df_merged0=df_merged0_\n",
        "df_merged1=df_merged1_\n",
        "df_merged2=df_merged2_\n",
        "\n",
        "frames = [df_merged0,df_merged1,df_merged2]\n",
        "\n",
        "df_joined_drug = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up8C152jMdTn"
      },
      "source": [
        "df_joined_drug=df_joined_drug['drugname'].groupby([df_joined_drug.primaryid,df_joined_drug.caseid,df_joined_drug.lot_num,df_joined_drug.nda_num, df_joined_drug.event_dt, \n",
        "                                                           df_joined_drug.occr_country, df_joined_drug.pt,\n",
        "                        df_joined_drug.reporter_country,df_joined_drug.CNTRY_NAME,df_joined_drug.fda_dt]).apply(list).reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4UQsz-cMdTo"
      },
      "source": [
        "#len(df_1.pt.iloc[5])\n",
        "#df_1.pt.iloc[5]\n",
        "\n",
        "df_joined_drug[\"count_drugs\"] = np.nan\n",
        "lenghts = []\n",
        "for index, row in df_joined_drug.iterrows():\n",
        "        #print(row[[\"geometry\",\"GaugeLID\"]])\n",
        "\n",
        "    length = len(df_joined_drug.drugname.iloc[index])\n",
        "    lenghts.append(length)\n",
        "df_joined_drug['count_drugs'] = lenghts   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIw-xhvSMdTp"
      },
      "source": [
        "df_joined_drug_=df_joined_drug[df_joined_drug['count_drugs']==1]\n",
        "df_joined_drug_['drugname'] = df_joined_drug_['drugname'].astype(str)\n",
        "\n",
        "df_joined_drug_['drugname'] = df_joined_drug_['drugname'].str.lstrip('[')\n",
        "df_joined_drug_['drugname'] = df_joined_drug_['drugname'].str.rstrip(']')\n",
        "df_joined_drug_['drugname'] = df_joined_drug_['drugname'].str.lstrip(\"'\")\n",
        "df_joined_drug_['drugname'] = df_joined_drug_['drugname'].str.rstrip(\"'\")\n",
        "\n",
        "df_joined_drug_.info()\n",
        "#df_joined_drug_.drugname.value_counts()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVdep1TJMdTq"
      },
      "source": [
        "df_joined_drug_.drugname.value_counts().head(20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUZk4SoCMdTr"
      },
      "source": [
        "stop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwwAj7MlMdTs"
      },
      "source": [
        "df_= df_joined_drug_[df_joined_drug_['drugname'].isin(['nivolumab'])]\n",
        "#df_joined_drug_.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HALBn6ijMdTs"
      },
      "source": [
        "#df_joined_drug.drugname.value_counts()\n",
        "df_ = df_.filter(['primaryid','caseid','lot_num', 'nda_num','pt','drugname','prod_ai','reporter_country','occr_country','event_dt','CNTRY_NAME','fda_dt', 'geometry'])\n",
        "\n",
        "df_.CNTRY_NAME.value_counts().head(20)\n",
        "#df_.prod_ai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oUuvDMvMdTt"
      },
      "source": [
        "total_rows = df_['primaryid'].count()\n",
        "#print(total_rows2+1)\n",
        "print('total rows: ', total_rows+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21wj5_aMdTt"
      },
      "source": [
        "total_rows = df_['primaryid'].count()\n",
        "print('total rows: ',total_rows+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShX3feSpMdTu"
      },
      "source": [
        "plt.style.use(['dark_background'])\n",
        "plt.style.use('ggplot')\n",
        "plt.figure(num=None, figsize=(15, 15), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.rc('xtick', labelsize=20) \n",
        "plt.rc('ytick', labelsize=20) \n",
        "df_['event_dt'].groupby(df_[\"event_dt\"].dt.year).count().plot(kind=\"bar\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys9SknHrMdTu"
      },
      "source": [
        "#df_natalizumab.drop(['fda_dt'], axis=1,inplace=True)\n",
        "df_['one'] = int(1)\n",
        "df_['year'] = pd.DatetimeIndex(df_['event_dt']).year\n",
        "df_['quarter'] = pd.DatetimeIndex(df_['event_dt']).quarter\n",
        "\n",
        "df_.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOwslOiVMdTu"
      },
      "source": [
        "os.chdir(r\"D:\\Research\\FAERS_Public_LDA\\Data\\Analysis_Ready_data\\Extracted_data\")\n",
        "#df_.to_csv('df_enbrel_europe.csv')\n",
        "#df_.to_csv('df_remicade_europe.csv')\n",
        "#df_.to_csv('df_humira_europe.csv')\n",
        "#df_.to_csv('df_dexamethasone_europe.csv')\n",
        "df_.to_csv('df_nivolumab_europe.csv')\n",
        "#xarelto\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh73fABTMdTv"
      },
      "source": [
        "df_.primaryid.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJuGP60RMdTv"
      },
      "source": [
        "df_=df_[df_.occr_country.str.contains('de|se|si',na=False, case=False)]\n",
        "df_= df_[df_.pt.str.contains('Fall',na=False, regex=True, case=False)]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPk6dIruMdTv"
      },
      "source": [
        "df_.head()\n",
        "df_1=df_['pt'].groupby([df_.primaryid,df_.caseid,df_.lot_num,df_.nda_num, df_.event_dt, df_.occr_country, df_.drugname,\n",
        "                        df_.reporter_country,df_.CNTRY_NAME,df_.fda_dt,\n",
        "                        df_.one,df_.year,df_.quarter]).apply(list).reset_index()\n",
        "\n",
        "\n",
        "\n",
        "df_1[\"count_pt\"] = np.nan\n",
        "lenghts = []\n",
        "for index, row in df_1.iterrows():\n",
        "        #print(row[[\"geometry\",\"GaugeLID\"]])\n",
        "\n",
        "    length = len(df_1.pt.iloc[index])\n",
        "    lenghts.append(length)\n",
        "df_1['count_pt'] = lenghts   \n",
        "\n",
        "df_1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyhKhgREMdTw"
      },
      "source": [
        "df_.head()\n",
        "df_.pt = df_.pt.astype(str)\n",
        "df_['pt'] = df_['pt'].str.strip()\n",
        "df_['pt'] = df_['pt'].str.strip(',')\n",
        "df_['pt']=df_['pt'].str.lower()\n",
        "\n",
        "df_1=df_['occr_country'].groupby([df_.pt,df_.drugname,df_.event_dt,df_.year,df_.quarter]).apply(list).reset_index()\n",
        "\n",
        "\n",
        "df_1[\"count_occr_country\"] = np.nan\n",
        "lenghts = []\n",
        "for index, row in df_1.iterrows():\n",
        "        #print(row[[\"geometry\",\"GaugeLID\"]])\n",
        "\n",
        "    length = len(df_1.occr_country.iloc[index])\n",
        "    lenghts.append(length)\n",
        "df_1['count_occr_country'] = lenghts  \n",
        "#df_1['occr_country'] = df_1['occr_country'].str.split(',').apply(set).str.join(',')\n",
        "\n",
        "\n",
        "df_1.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gRWnxjmMdTw"
      },
      "source": [
        "df_1[df_1['count_occr_country']>=2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYHZgNsyMdTw"
      },
      "source": [
        "#df_1[df_1.pt=='fall']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwO8m97-MdTx"
      },
      "source": [
        "df_1.primaryid = df_1.primaryid.astype(str)\n",
        "pid= '100041803'\n",
        "df_1_=df_1[df_1.primaryid.str.contains(pid)]\n",
        "df_1_.pt.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYWlYvlMdTx"
      },
      "source": [
        "#os.chdir(r\"G:\\Research\\FAERS_Public\\Data\\Analysis_Ready_data\\Extracted_data\")\n",
        "#df_1.to_csv('df_duodopa_europe_PT_joined.csv')\n",
        "df_1.to_csv('df_nivolumab_europe_PT_joined.csv')\n",
        "#df_1.to_csv('df_dexamethasone_europe_PT_joined.csv')\n",
        "#df_1.to_csv('df_omeprazole_europe_PT_joined.csv')\n",
        "#df_1.to_csv('df_remicade_europe_occr_country_joined.csv')\n",
        "#df_1.to_csv('df_methotrexate_europe_PT_joined.csv')\n",
        "#df_1.to_csv('df_remicade_europe_PT_joined.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f7HQp1BMdTy"
      },
      "source": [
        "df_1[df_1.occr_country=='dk']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxbDmepBMdTz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}