{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules \n",
    "#from mlxtend.preprocessing import OnehotTransactions\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "import smart_open\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing \"os\" operating system\n",
      "pandas\n",
      "geopandas\n",
      "shapely\n",
      "numpy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\patsy\\constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels\n",
      "seaborn\n",
      "matplotlib\n"
     ]
    }
   ],
   "source": [
    "#importing modules\n",
    "import os \n",
    "print('importing \"os\" operating system')\n",
    "from io import BytesIO\n",
    "#from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "print('pandas')\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "print('geopandas')\n",
    "from shapely.geometry import Point\n",
    "print('shapely')\n",
    "import numpy as np\n",
    "print('numpy')\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "print('statsmodels')\n",
    "#import pysal as ps\n",
    "#print('pysal')\n",
    "import seaborn as sns\n",
    "print('seaborn')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "print('matplotlib')\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist, jaccard\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "#from sklearn.metrics import jaccard_similarity_score\n",
    "from difflib import SequenceMatcher\n",
    "import difflib as dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approri part 2 and spatial auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugname:  xarelto\n",
      "topic 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#drugname = 'tysabri' #, , , , \n",
    "#drugnamepath = drugname[:6]\n",
    "#temporal = 'year'\n",
    "#drugnamepath\n",
    "#topk = 2\n",
    "\n",
    "drugname = 'xarelto'#eliquis, xarelto, pradaxa\n",
    "print('drugname: ', drugname)\n",
    "\n",
    "drugnamepath = drugname[:6]\n",
    "temporal = str('year')\n",
    "drugnamepath\n",
    "topics=5\n",
    "topk = 'top'+str(topics)\n",
    "        \n",
    "#topk = 'tp'+str(k)\n",
    "print('topic', topics)\n",
    "        #topk = 'tp10'\n",
    "        #tpk\n",
    "kk=topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xarelt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugnamepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['Acute kidney injury, Renal artery occlusion']\n",
       "1    ['Abnormal dreams, Aphagia, Dry mouth, Fatigue...\n",
       "2    ['Gastric haemorrhage, Haemoptysis'\\n 'Interna...\n",
       "3                      ['Gastric ulcer, Haematemesis']\n",
       "4                                          ['Aphasia']\n",
       "Name: FaersValue, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_dirpath1 = r\"D:\\Research\\FAERS_Public\\Data\\Analysis_Ready_data\"+str('\\\\')+str(topk)+str('\\\\')+str(drugnamepath)+\"_itemset_joinedPT\\\\\"+str(temporal)+\"_nai\"\n",
    "data_dirpath1 = r\"D:\\Research\\FAERS_Public_Similarity\\Data\\analysis_ready\\df_xarelto_europe.csv\"\n",
    "#\"D:\\Research\\FAERS_Public_LDA\\Data\\Analysis_Ready_data\\Extracted_data\\df_xarelto_europe_PT_joined.csv\"\n",
    "#os.chdir(data_dirpath1)\n",
    "data_dirpath1\n",
    "#print(os.getcwd())\n",
    "Faers_comparision = pd.read_csv(data_dirpath1)\n",
    "Faers_comparision.rename({'pt_unique': 'FaersValue'}, axis=1, inplace=True)\n",
    "#Faers_comparision['pt_unique']  = ','.join(Faers_comparision['pt_unique'] )\n",
    "Faers_comparision['FaersValue']  = Faers_comparision['FaersValue'] .apply(lambda x: ', '.join(x.split(\"' '\")))\n",
    "\n",
    "Faers_comparision['FaersValue'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>primaryid</th>\n",
       "      <th>caseid</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occr_country</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>event_dt</th>\n",
       "      <th>pt</th>\n",
       "      <th>prod_ai</th>\n",
       "      <th>...</th>\n",
       "      <th>indi_pt</th>\n",
       "      <th>drugname_unique</th>\n",
       "      <th>FaersValue</th>\n",
       "      <th>prod_ai_unique</th>\n",
       "      <th>indi_pt_unique</th>\n",
       "      <th>count_drugs</th>\n",
       "      <th>drugname_unique_string</th>\n",
       "      <th>one</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20238</td>\n",
       "      <td>107248571</td>\n",
       "      <td>10724857</td>\n",
       "      <td>56.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ro</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>[['Acute kidney injury', 'Acute kidney injury'...</td>\n",
       "      <td>[['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[['Atrial fibrillation', 'Cerebrovascular acci...</td>\n",
       "      <td>['xarelto']</td>\n",
       "      <td>['Acute kidney injury, Renal artery occlusion']</td>\n",
       "      <td>['RIVAROXABAN']</td>\n",
       "      <td>['Atrial fibrillation' 'Cerebrovascular accide...</td>\n",
       "      <td>1</td>\n",
       "      <td>xarelto</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21453</td>\n",
       "      <td>107405402</td>\n",
       "      <td>10740540</td>\n",
       "      <td>76.0</td>\n",
       "      <td>M</td>\n",
       "      <td>gb</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>[['Abnormal dreams', 'Aphagia', 'Dry mouth', '...</td>\n",
       "      <td>[['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[['Product used for unknown indication', 'Prod...</td>\n",
       "      <td>['xarelto']</td>\n",
       "      <td>['Abnormal dreams, Aphagia, Dry mouth, Fatigue...</td>\n",
       "      <td>['RIVAROXABAN']</td>\n",
       "      <td>['Product used for unknown indication']</td>\n",
       "      <td>1</td>\n",
       "      <td>xarelto</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  primaryid    caseid   age sex occr_country         COUNTRY  \\\n",
       "0       20238  107248571  10724857  56.0   M           ro         Romania   \n",
       "1       21453  107405402  10740540  76.0   M           gb  United Kingdom   \n",
       "\n",
       "     event_dt                                                 pt  \\\n",
       "0  2015-01-07  [['Acute kidney injury', 'Acute kidney injury'...   \n",
       "1  2015-01-09  [['Abnormal dreams', 'Aphagia', 'Dry mouth', '...   \n",
       "\n",
       "                                             prod_ai  ...  \\\n",
       "0  [['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...  ...   \n",
       "1  [['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...  ...   \n",
       "\n",
       "                                             indi_pt drugname_unique  \\\n",
       "0  [['Atrial fibrillation', 'Cerebrovascular acci...     ['xarelto']   \n",
       "1  [['Product used for unknown indication', 'Prod...     ['xarelto']   \n",
       "\n",
       "                                          FaersValue   prod_ai_unique  \\\n",
       "0    ['Acute kidney injury, Renal artery occlusion']  ['RIVAROXABAN']   \n",
       "1  ['Abnormal dreams, Aphagia, Dry mouth, Fatigue...  ['RIVAROXABAN']   \n",
       "\n",
       "                                      indi_pt_unique count_drugs  \\\n",
       "0  ['Atrial fibrillation' 'Cerebrovascular accide...           1   \n",
       "1            ['Product used for unknown indication']           1   \n",
       "\n",
       "   drugname_unique_string one  year  quarter  \n",
       "0                 xarelto   1  2015        1  \n",
       "1                 xarelto   1  2015        1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Faers_comparision.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>primaryid</th>\n",
       "      <th>caseid</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occr_country</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>event_dt</th>\n",
       "      <th>pt</th>\n",
       "      <th>prod_ai</th>\n",
       "      <th>...</th>\n",
       "      <th>indi_pt</th>\n",
       "      <th>drugname_unique</th>\n",
       "      <th>FaersValue</th>\n",
       "      <th>prod_ai_unique</th>\n",
       "      <th>indi_pt_unique</th>\n",
       "      <th>count_drugs</th>\n",
       "      <th>drugname_unique_string</th>\n",
       "      <th>one</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20238</td>\n",
       "      <td>107248571</td>\n",
       "      <td>10724857</td>\n",
       "      <td>56.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ro</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>[['Acute kidney injury', 'Acute kidney injury'...</td>\n",
       "      <td>[['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[['Atrial fibrillation', 'Cerebrovascular acci...</td>\n",
       "      <td>['xarelto']</td>\n",
       "      <td>['Acute kidney injury, Renal artery occlusion']</td>\n",
       "      <td>['RIVAROXABAN']</td>\n",
       "      <td>['Atrial fibrillation' 'Cerebrovascular accide...</td>\n",
       "      <td>1</td>\n",
       "      <td>xarelto</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21453</td>\n",
       "      <td>107405402</td>\n",
       "      <td>10740540</td>\n",
       "      <td>76.0</td>\n",
       "      <td>M</td>\n",
       "      <td>gb</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>[['Abnormal dreams', 'Aphagia', 'Dry mouth', '...</td>\n",
       "      <td>[['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[['Product used for unknown indication', 'Prod...</td>\n",
       "      <td>['xarelto']</td>\n",
       "      <td>['Abnormal dreams, Aphagia, Dry mouth, Fatigue...</td>\n",
       "      <td>['RIVAROXABAN']</td>\n",
       "      <td>['Product used for unknown indication']</td>\n",
       "      <td>1</td>\n",
       "      <td>xarelto</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  primaryid    caseid   age sex occr_country         COUNTRY  \\\n",
       "0       20238  107248571  10724857  56.0   M           ro         Romania   \n",
       "1       21453  107405402  10740540  76.0   M           gb  United Kingdom   \n",
       "\n",
       "     event_dt                                                 pt  \\\n",
       "0  2015-01-07  [['Acute kidney injury', 'Acute kidney injury'...   \n",
       "1  2015-01-09  [['Abnormal dreams', 'Aphagia', 'Dry mouth', '...   \n",
       "\n",
       "                                             prod_ai  ...  \\\n",
       "0  [['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...  ...   \n",
       "1  [['RIVAROXABAN', 'RIVAROXABAN', 'RIVAROXABAN',...  ...   \n",
       "\n",
       "                                             indi_pt drugname_unique  \\\n",
       "0  [['Atrial fibrillation', 'Cerebrovascular acci...     ['xarelto']   \n",
       "1  [['Product used for unknown indication', 'Prod...     ['xarelto']   \n",
       "\n",
       "                                          FaersValue   prod_ai_unique  \\\n",
       "0    ['Acute kidney injury, Renal artery occlusion']  ['RIVAROXABAN']   \n",
       "1  ['Abnormal dreams, Aphagia, Dry mouth, Fatigue...  ['RIVAROXABAN']   \n",
       "\n",
       "                                      indi_pt_unique count_drugs  \\\n",
       "0  ['Atrial fibrillation' 'Cerebrovascular accide...           1   \n",
       "1            ['Product used for unknown indication']           1   \n",
       "\n",
       "   drugname_unique_string one  year  quarter  \n",
       "0                 xarelto   1  2015        1  \n",
       "1                 xarelto   1  2015        1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Faers_comparision['spatial'], Faers_comparision['temporal'] = Faers_comparision['spatiotemporal'].str.split('_', 1).str\n",
    "Faers_comparision =Faers_comparision[(Faers_comparision['year']>=2015)&(Faers_comparision['year']<=2019)]\n",
    "#Faers_comparision = Faers_comparision.groupby(['occr_country', 'year'],as_index=False).agg({ 'drugname': lambda x: list(x),'FaersValue': lambda x: list(x)})\n",
    "#Faers_comparision['drugname']=list(map(set,Faers_comparision['drugname']))\n",
    "\n",
    "Faers_comparision.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1326 entries, 0 to 1325\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              1326 non-null   int64  \n",
      " 1   primaryid               1326 non-null   int64  \n",
      " 2   caseid                  1326 non-null   int64  \n",
      " 3   age                     1326 non-null   float64\n",
      " 4   sex                     1326 non-null   object \n",
      " 5   occr_country            1326 non-null   object \n",
      " 6   COUNTRY                 1326 non-null   object \n",
      " 7   event_dt                1326 non-null   object \n",
      " 8   pt                      1326 non-null   object \n",
      " 9   prod_ai                 1326 non-null   object \n",
      " 10  drugname                1326 non-null   object \n",
      " 11  indi_pt                 1326 non-null   object \n",
      " 12  drugname_unique         1326 non-null   object \n",
      " 13  FaersValue              1326 non-null   object \n",
      " 14  prod_ai_unique          1326 non-null   object \n",
      " 15  indi_pt_unique          1326 non-null   object \n",
      " 16  count_drugs             1326 non-null   int64  \n",
      " 17  drugname_unique_string  1326 non-null   object \n",
      " 18  one                     1326 non-null   int64  \n",
      " 19  year                    1326 non-null   int64  \n",
      " 20  quarter                 1326 non-null   int64  \n",
      "dtypes: float64(1), int64(7), object(13)\n",
      "memory usage: 227.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed.Askar\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "Faers_comparision.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].astype(str)\n",
    "\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].astype(str)\n",
    "Faers_comparision['FaersValue']=Faers_comparision.FaersValue.str.split(',')\n",
    "\n",
    "Faers_comparision.FaersValue = Faers_comparision.FaersValue.apply(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Acute kidney injury,  Renal artery occlusion]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.strip()\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lower()\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(u\"/\",\", \")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(u\"\\\\\\\\\", \", \")\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(u\"' \",\"'\")\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace('\\n',\"\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(' \\n',\"\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace('\\n ',\"\")\n",
    "\n",
    "Faers_comparision['FaersValue'] = [' '.join(c.split()) for c in Faers_comparision['FaersValue'].astype(str)]\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r\"\\n\",  ' ', regex=True)\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(r\"[\\\"\\']\", '')\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(r\"[\\\"\\]\", '')\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(',,,',',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(',,',',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace('{','')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace('','')\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str[1:]\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str[:-1]\n",
    "Faers_comparision['FaersValue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Renal artery occlusion], [Acute kidney injury'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(r\"[\\\"\\']\", '')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(', ')\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].apply(lambda x: ', '.join(sorted(x.split(','))))\n",
    "\n",
    "Faers_comparision['FaersValue'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acute kidney injury, renal artery occlusion'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(r\"[\\\"\\']}{}\", '')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(\"''\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].apply(lambda x: ', '.join(sorted(x.split(','))))\n",
    "\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(\"''\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(\"''\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(\"''\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip('}')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(\"''\")\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.replace(r\"}\", '')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.rstrip(' ,')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(', ')\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(' ,')\n",
    "Faers_comparision['FaersValue'] =Faers_comparision['FaersValue'].str.split(',').apply(set).str.join(',')\n",
    "Faers_comparision['FaersValue'] =Faers_comparision['FaersValue'].str.lower()\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str[1:]\n",
    "Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str[:-1]\n",
    "Faers_comparision['FaersValue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xarelto'\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Faers_comparision['year']=Faers_comparision['year'].astype(str)\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(',')\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(', ')\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.lstrip(' ,')\n",
    "#Faers_comparision['FaersValue'] = Faers_comparision['FaersValue'].str.strip(',')\n",
    "#Faers_comparision['FaersValue'] = [' '.join(c.split()) for c in Faers_comparision['FaersValue'].astype(str)]\n",
    "Faers_comparision['drugname_unique'] = Faers_comparision['drugname_unique'].str[1:]\n",
    "Faers_comparision['drugname_unique'] = Faers_comparision['drugname_unique'].str[:-1]\n",
    "Faers_comparision['drugname_unique'] = Faers_comparision['drugname_unique'].str.lstrip(\"''\")\n",
    "\n",
    "Faers_comparision['drugname_unique'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am',\n",
       " 'at',\n",
       " 'ba',\n",
       " 'be',\n",
       " 'bg',\n",
       " 'by',\n",
       " 'ch',\n",
       " 'cz',\n",
       " 'de',\n",
       " 'dk',\n",
       " 'ee',\n",
       " 'es',\n",
       " 'fi',\n",
       " 'fr',\n",
       " 'gb',\n",
       " 'ge',\n",
       " 'gr',\n",
       " 'hr',\n",
       " 'hu',\n",
       " 'ie',\n",
       " 'is',\n",
       " 'it',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lv',\n",
       " 'nl',\n",
       " 'no',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'ro',\n",
       " 'se',\n",
       " 'si',\n",
       " 'sk',\n",
       " 'tr',\n",
       " 'ua'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_list = Faers_comparision['occr_country'].to_list()\n",
    "europe_ =set(spatial_list)\n",
    "europe_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "europe = ['AL', 'AD', 'AM', 'AT', 'BY', 'BE', 'BA', 'BG', 'CH','CY', 'CZ','DE',\n",
    "        'DK', 'EE', 'ES', 'FO', 'FI', 'FR','GB', 'GE', 'GI', 'GR', 'HU', 'HR',\n",
    "        'IE', 'IS','IT','LU','LT', 'LV', 'MC', 'MK', 'MT', 'NO', 'NL', 'PL',\n",
    "        'PT', 'RO', 'SE', 'SI', 'SK', 'SM', 'TR', 'UA', 'VA']#LU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#europe = ['fi']#LU,FI,'BE','CZ',\n",
    "\n",
    "#europe = ['CH']\n",
    "europe_ = []\n",
    "for x in europe:\n",
    "    x = x.lower()\n",
    "    europe_.append(x)\n",
    "\n",
    "spatial_list =sorted(europe_)\n",
    "print(europe_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Research\\FAERS_Public_Similarity\\Data\\itemset_joinedPT\\nai\n"
     ]
    }
   ],
   "source": [
    "#data_dirpath1 = r\"D:\\Research\\FAERS_Public\\Data\\Analysis_Ready_data\"+str('\\\\')+str(topk)+str('\\\\')+str(drugnamepath)+\"_itemset_joinedPT\\\\\"+str(temporal_file)+\"_nai_\"\n",
    "#data_dirpath1=r\"D:\\Research\\FAERS_Public_Similarity\\Data\\itemset_joinedPT\\year_nai\"\n",
    "#os.chdir(data_dirpath1)\n",
    "#data_dirpath1\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 0 objects.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "collected = gc.collect()\n",
    "print (\"Garbage collector: collected %d objects.\" % (collected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_file='year'\n",
    "#df = Faers_comparision\n",
    "#df.head()\n",
    "#df[df.drugname_unique==drugname]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.occr_country == 'ch'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "\n",
    "def temporal(drugname):\n",
    "    drug_dataframe = Faers_comparision[Faers_comparision.drugname_unique == drugname]\n",
    "    return drug_dataframe\n",
    "\n",
    "def spatio(spatial_list):\n",
    "    state_dataframe = Faers_comparision[Faers_comparision.occr_country == spatial]\n",
    "    return spatio_dataframe\n",
    "\n",
    "\n",
    "\n",
    "def spatiotemporal(spatial,temporal):\n",
    "    #temp_dataframe = df[df.Generic_name_All_U.str.contains(drugname)]\n",
    "    #working_dataframe = temp_dataframe[temp_dataframe.STATE.str.contains(state)]\n",
    "    temp_dataframe = Faers_comparision[Faers_comparision[temporal_file] == temporal]\n",
    "    \n",
    "    working_dataframe = temp_dataframe[temp_dataframe.occr_country == spatial]\n",
    "    return working_dataframe\n",
    "\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Frequent Itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dk\n",
      "at\n",
      "se\n",
      "hu\n",
      "no\n",
      "am\n",
      "sk\n",
      "by\n",
      "si\n",
      "de\n",
      "bg\n",
      "ro\n",
      "lv\n",
      "lu\n",
      "pt\n",
      "cz\n",
      "fi\n",
      "ee\n",
      "ba\n",
      "gr\n",
      "ua\n",
      "tr\n",
      "nl\n",
      "gb\n",
      "is\n",
      "ie\n",
      "ge\n",
      "ch\n",
      "it\n",
      "fr\n",
      "lt\n",
      "pl\n",
      "be\n",
      "es\n",
      "hr\n",
      "alllll Done year\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "os.chdir(r\"D:\\Research\\FAERS_Public_Similarity\\Data\\itemset_joinedPT\\nai\")\n",
    "#len(df[df.occr_country=='lu'].index)\n",
    "#time_list = ['1','2','3','4']#\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "#minsup = 0.9\n",
    "if temporal_file == 'year':\n",
    "#time_list = ['1','2','3','4']\n",
    "    #time_list = ['2015','2016','2017', '2018']\n",
    "    alreadyrunfile = []\n",
    "    row_count_dict = {}\n",
    "    row_count = []\n",
    "    filenames = []\n",
    "    d = {}\n",
    "    #for spatial in spatial_list:\n",
    "    for spatial in europe_:\n",
    "        #x = spatio(spatial)\n",
    "        print(spatial)\n",
    "        x = Faers_comparision[Faers_comparision.occr_country == spatial]\n",
    "        row_count.append(len(x.index))\n",
    "\n",
    "\n",
    "\n",
    "        dataset = []\n",
    "        #print(x)\n",
    "        for xx in x['FaersValue']:\n",
    "            dataset.append(xx.split(','))\n",
    "            pass\n",
    "        import pandas as pd\n",
    "        from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "        oht = TransactionEncoder()\n",
    "        oht_ary = oht.fit(dataset).transform(dataset)\n",
    "        df4 = pd.DataFrame(oht_ary, columns=oht.columns_)\n",
    "        df4\n",
    "        from mlxtend.frequent_patterns import apriori\n",
    "        for x1 in np.geomspace(1, 0.0005, num=50):#(1, 0.005, num=50):\n",
    "            minsup = x1\n",
    "\n",
    "\n",
    "            frequent_itemsets = apriori(df4, min_support=minsup, use_colnames=True)#0.05\n",
    "            frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].astype(str)\n",
    "            frequent_itemsets['itemsets']  = frequent_itemsets['itemsets'].astype(str).replace('frozenset', '', regex=True)\n",
    "            frequent_itemsets['itemsets'] =frequent_itemsets.itemsets.str.rstrip(\")\")\n",
    "            frequent_itemsets['itemsets'] =frequent_itemsets.itemsets.str.lstrip(\"(\")\n",
    "            frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
    "            frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "            if len(frequent_itemsets.index)>=1:\n",
    "\n",
    "\n",
    "            #print(len(frequent_itemsets.index))\n",
    "                #frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "                filename = spatial+\"_\"+str('nai')#[-7:]\n",
    "\n",
    "                frequent_itemsets.to_csv(filename+'.csv', float_format='%.5f')\n",
    "                filenames.append(filename)\n",
    "                row_count_dict = dict(zip(filenames,row_count))\n",
    "                #print(filename)\n",
    "                alreadyrunfile.append(filename[0:2]+filename[-1:])\n",
    "                    #print(filename[0:2],filename[-1:])\n",
    "                gc.collect()\n",
    "                collected = gc.collect()\n",
    "                break\n",
    "            #print(minsup)\n",
    "            for xyz in range(0,len(alreadyrunfile)):\n",
    "                    #print(alreadyrunfile[xyz][0:2] + alreadyrunfile[xyz][-1:])\n",
    "            #print(x)\n",
    "                    #df = df[~(df.occr_country==str(alreadyrunfile[xyz][0:2])) & (df['quarter']==str(alreadyrunfile[xyz][-1:]))]  \n",
    "                x = x[~(x.occr_country==str(alreadyrunfile[xyz][0:2]))] #& (x[temporal_file]==str(alreadyrunfile[xyz][-1:]))]  \n",
    "                #print (\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "        collected = gc.collect()\n",
    "    #print (\"Garbage collector: collected %d objects.\" % (collected))\n",
    "print('alllll Done year') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial temporal Frequent Itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dk 2015\n",
      "dk 2016\n",
      "dk 2017\n",
      "dk 2018\n",
      "dk 2019\n",
      "at 2015\n",
      "at 2016\n",
      "at 2017\n",
      "at 2018\n",
      "at 2019\n",
      "se 2015\n",
      "se 2016\n",
      "se 2017\n",
      "se 2018\n",
      "se 2019\n",
      "hu 2015\n",
      "hu 2016\n",
      "hu 2017\n",
      "hu 2018\n",
      "hu 2019\n",
      "no 2015\n",
      "no 2016\n",
      "no 2017\n",
      "no 2018\n",
      "no 2019\n",
      "am 2015\n",
      "am 2016\n",
      "am 2017\n",
      "am 2018\n",
      "am 2019\n",
      "sk 2015\n",
      "sk 2016\n",
      "sk 2017\n",
      "sk 2018\n",
      "sk 2019\n",
      "by 2015\n",
      "by 2016\n",
      "by 2017\n",
      "by 2018\n",
      "by 2019\n",
      "si 2015\n",
      "si 2016\n",
      "si 2017\n",
      "si 2018\n",
      "si 2019\n",
      "de 2015\n",
      "de 2016\n",
      "de 2017\n",
      "de 2018\n",
      "de 2019\n",
      "bg 2015\n",
      "bg 2016\n",
      "bg 2017\n",
      "bg 2018\n",
      "bg 2019\n",
      "ro 2015\n",
      "ro 2016\n",
      "ro 2017\n",
      "ro 2018\n",
      "ro 2019\n",
      "lv 2015\n",
      "lv 2016\n",
      "lv 2017\n",
      "lv 2018\n",
      "lv 2019\n",
      "lu 2015\n",
      "lu 2016\n",
      "lu 2017\n",
      "lu 2018\n",
      "lu 2019\n",
      "pt 2015\n",
      "pt 2016\n",
      "pt 2017\n",
      "pt 2018\n",
      "pt 2019\n",
      "cz 2015\n",
      "cz 2016\n",
      "cz 2017\n",
      "cz 2018\n",
      "cz 2019\n",
      "fi 2015\n",
      "fi 2016\n",
      "fi 2017\n",
      "fi 2018\n",
      "fi 2019\n",
      "ee 2015\n",
      "ee 2016\n",
      "ee 2017\n",
      "ee 2018\n",
      "ee 2019\n",
      "ba 2015\n",
      "ba 2016\n",
      "ba 2017\n",
      "ba 2018\n",
      "ba 2019\n",
      "gr 2015\n",
      "gr 2016\n",
      "gr 2017\n",
      "gr 2018\n",
      "gr 2019\n",
      "ua 2015\n",
      "ua 2016\n",
      "ua 2017\n",
      "ua 2018\n",
      "ua 2019\n",
      "tr 2015\n",
      "tr 2016\n",
      "tr 2017\n",
      "tr 2018\n",
      "tr 2019\n",
      "nl 2015\n",
      "nl 2016\n",
      "nl 2017\n",
      "nl 2018\n",
      "nl 2019\n",
      "gb 2015\n",
      "gb 2016\n",
      "gb 2017\n",
      "gb 2018\n",
      "gb 2019\n",
      "is 2015\n",
      "is 2016\n",
      "is 2017\n",
      "is 2018\n",
      "is 2019\n",
      "ie 2015\n",
      "ie 2016\n",
      "ie 2017\n",
      "ie 2018\n",
      "ie 2019\n",
      "ge 2015\n",
      "ge 2016\n",
      "ge 2017\n",
      "ge 2018\n",
      "ge 2019\n",
      "ch 2015\n",
      "ch 2016\n",
      "ch 2017\n",
      "ch 2018\n",
      "ch 2019\n",
      "it 2015\n",
      "it 2016\n",
      "it 2017\n",
      "it 2018\n",
      "it 2019\n",
      "fr 2015\n",
      "fr 2016\n",
      "fr 2017\n",
      "fr 2018\n",
      "fr 2019\n",
      "lt 2015\n",
      "lt 2016\n",
      "lt 2017\n",
      "lt 2018\n",
      "lt 2019\n",
      "pl 2015\n",
      "pl 2016\n",
      "pl 2017\n",
      "pl 2018\n",
      "pl 2019\n",
      "be 2015\n",
      "be 2016\n",
      "be 2017\n",
      "be 2018\n",
      "be 2019\n",
      "es 2015\n",
      "es 2016\n",
      "es 2017\n",
      "es 2018\n",
      "es 2019\n",
      "hr 2015\n",
      "hr 2016\n",
      "hr 2017\n",
      "hr 2018\n",
      "hr 2019\n",
      "alllll Done year\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "#len(df[df.occr_country=='lu'].index)\n",
    "#time_list = ['1','2','3','4']#\n",
    "os.chdir(r\"D:\\Research\\FAERS_Public_Similarity\\Data\\itemset_joinedPT\\year_nai\")\n",
    "from __future__ import division\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "#minsup = 0.9\n",
    "if temporal_file == 'year':\n",
    "#time_list = ['1','2','3','4']\n",
    "    time_list = ['2015','2016','2017', '2018', '2019']\n",
    "    alreadyrunfile = []\n",
    "    row_count_dict = {}\n",
    "    row_count = []\n",
    "    filenames = []\n",
    "    d = {}\n",
    "    #for spatial in spatial_list:\n",
    "    for spatial in europe_:\n",
    "\n",
    "        for temporal in time_list:\n",
    "            print (spatial,temporal)\n",
    "            d = {}\n",
    "            x = spatiotemporal(spatial, temporal)\n",
    "\n",
    "            row_count.append(len(x.index))\n",
    "\n",
    "\n",
    "\n",
    "            dataset = []\n",
    "            #print(x)\n",
    "            for xx in x['FaersValue']:\n",
    "                dataset.append(xx.split(','))\n",
    "                pass\n",
    "            import pandas as pd\n",
    "            from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "            oht = TransactionEncoder()\n",
    "            oht_ary = oht.fit(dataset).transform(dataset)\n",
    "            df4 = pd.DataFrame(oht_ary, columns=oht.columns_)\n",
    "            df4\n",
    "            from mlxtend.frequent_patterns import apriori\n",
    "            for x1 in np.geomspace(1, 0.0005, num=50):#(1, 0.005, num=50):\n",
    "                minsup = x1\n",
    "        \n",
    "\n",
    "                frequent_itemsets = apriori(df4, min_support=minsup, use_colnames=True)#0.05\n",
    "                frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].astype(str)\n",
    "                frequent_itemsets['itemsets']  = frequent_itemsets['itemsets'].astype(str).replace('frozenset', '', regex=True)\n",
    "                frequent_itemsets['itemsets'] =frequent_itemsets.itemsets.str.rstrip(\")\")\n",
    "                frequent_itemsets['itemsets'] =frequent_itemsets.itemsets.str.lstrip(\"(\")\n",
    "                frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].str.translate({None: \",!.; ''-@!%^&*)(\"})\n",
    "                frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "                if len(frequent_itemsets.index)>=5:\n",
    "    \n",
    "\n",
    "                #print(len(frequent_itemsets.index))\n",
    "                    #frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "                    filename = spatial+\"_\"+str(temporal_file)+\"_\"+temporal#[-7:]\n",
    "\n",
    "                    frequent_itemsets.to_csv(filename+'.csv', float_format='%.5f')\n",
    "                    filenames.append(filename)\n",
    "                    row_count_dict = dict(zip(filenames,row_count))\n",
    "                    #print(filename)\n",
    "                    alreadyrunfile.append(filename[0:2]+filename[-1:])\n",
    "                        #print(filename[0:2],filename[-1:])\n",
    "                    gc.collect()\n",
    "                    collected = gc.collect()\n",
    "                    break\n",
    "                #print(minsup)\n",
    "                for xyz in range(0,len(alreadyrunfile)):\n",
    "                        #print(alreadyrunfile[xyz][0:2] + alreadyrunfile[xyz][-1:])\n",
    "                #print(x)\n",
    "                        #df = df[~(df.occr_country==str(alreadyrunfile[xyz][0:2])) & (df['quarter']==str(alreadyrunfile[xyz][-1:]))]  \n",
    "                    x = x[~(x.occr_country==str(alreadyrunfile[xyz][0:2])) & (x[temporal_file]==str(alreadyrunfile[xyz][-1:]))]  \n",
    "                    #print (\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "            collected = gc.collect()\n",
    "        #print (\"Garbage collector: collected %d objects.\" % (collected))\n",
    "    print('alllll Done year') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "number of countries =  7.0\n",
      "countries list =  {'nl', 'it', 'fr', 'gb', 'de', 'fi', 'es'}\n",
      "delete these countries ['1d', 'am', 'at', 'ba', 'be', 'bg', 'ch', 'dk', 'ee', 'gr', 'hr', 'hu', 'ie', 'is', 'lt', 'lv', 'no', 'pl', 'ro', 'se', 'si', 'sk', 'tr']\n"
     ]
    }
   ],
   "source": [
    "data_dirpath1 =r\"D:\\Research\\FAERS_Public_Similarity\\Data\\itemset_joinedPT\\year_nai\"\n",
    "try:\n",
    "    \n",
    "    count_filename = []\n",
    "    filesuffix = []\n",
    "    true_list= []\n",
    "    filesuffixt = []\n",
    "    for x in os.listdir(data_dirpath1):\n",
    "        count_filename.append(x)\n",
    "    for x in range(0, len(count_filename)):\n",
    "        print(x)\n",
    "        filesuffix = []\n",
    "        filesuffix.append(x)\n",
    "        filesuffix.append(x+1)\n",
    "        filesuffix.append(x+2)\n",
    "        filesuffix.append(x+3)\n",
    "        filesuffix.append(x+4)\n",
    "        filesuffixt.append(count_filename[x][:2])\n",
    "        #print(filesuffixt)\n",
    "except IndexError:\n",
    "    pass\n",
    "#repeat_filenames = set(repeat_filename)\n",
    "for x in filesuffixt:\n",
    "    if filesuffixt.count(x)==5:\n",
    "        true_list.append(x)\n",
    "        pass\n",
    "print('number of countries = ',len(true_list)/5)\n",
    "count_countries = len(true_list)/5\n",
    "print('countries list = ',set(true_list))\n",
    "dellist =list(set(filesuffixt)-set(true_list))\n",
    "dellist =sorted(dellist, reverse=False)\n",
    "print('delete these countries', dellist)\n",
    "dfdel = pd.DataFrame({'delete files': dellist,\n",
    "                   'number of countries': count_countries})\n",
    "dfdel.to_csv('1delete_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alllll Done year\n"
     ]
    }
   ],
   "source": [
    "print('alllll Done year') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
